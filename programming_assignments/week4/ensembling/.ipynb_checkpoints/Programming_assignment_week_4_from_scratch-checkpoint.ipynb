{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.18.1\n",
      "pandas 1.0.1\n",
      "scipy 1.4.1\n",
      "sklearn 0.22.1\n",
      "lightgbm 2.3.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sklearn\n",
    "import scipy.sparse \n",
    "import lightgbm \n",
    "\n",
    "for p in [np, pd, scipy, sklearn, lightgbm]:\n",
    "    print (p.__name__, p.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 600)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm import notebook\n",
    "# import tqdm\n",
    "\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast_dtypes(df):\n",
    "    ''''\n",
    "        Changes column types in the dataframe: \n",
    "                \n",
    "                `float64` type to `float32`\n",
    "                `int64`   type to `int32`\n",
    "                \n",
    "        Downcasting dtypes will safe memory\n",
    "    '''\n",
    "    \n",
    "    # select columns to downcast\n",
    "    float_cols = [c for c in df if df[c].dtype == 'float64']\n",
    "    int_cols =   [c for c in df if df[c].dtype == 'int64']\n",
    "    \n",
    "    # downcast\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols]   = df[int_cols].astype(np.int32)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data frm the hard drive first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "zf = zipfile.ZipFile('../final_project/competitive-data-science-predict-future-sales.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv(zf.open('sales_train.csv'))\n",
    "shops = pd.read_csv(zf.open('shops.csv'))\n",
    "items = pd.read_csv(zf.open('items.csv'))\n",
    "item_cats = pd.read_csv(zf.open('item_categories.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and use only 3 shops for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = sales[sales['shop_id'].isin([26,27,28])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(301510, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a feature matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to prepare the features. This part is all implemented for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a grid with columns\n",
    "index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "\n",
    "# for every month we create a grid from all shop/itemss combinations from that month\n",
    "grid = []\n",
    "\n",
    "for block_num in sales['date_block_num'].unique():\n",
    "    cur_shops = sales.loc[sales['date_block_num'] == block_num, 'shop_id'].unique()\n",
    "    cur_items = sales.loc[sales['date_block_num'] == block_num, 'item_id'].unique()\n",
    "    grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])), dtype= 'int32'))\n",
    "                \n",
    "# turn the grid into a dataframe\n",
    "grid = pd.DataFrame(np.vstack(grid), columns= index_cols, dtype= np.int32)\n",
    "\n",
    "# groupby data to get shop-item-month aggregates\n",
    "gb = sales.groupby(index_cols, as_index= False).agg({'item_cnt_day': 'sum'})\n",
    "\n",
    "# rename item_cnt_day as target\n",
    "gb.rename(columns= {'item_cnt_day': 'target'}, inplace= True)\n",
    "\n",
    "# join it to the grid\n",
    "all_data = pd.merge(grid, gb, how= 'left', on= index_cols).fillna(0)\n",
    "\n",
    "\n",
    "# sames as above with shop-month (item is not included) aggregates\n",
    "gb = sales.groupby(['shop_id', 'date_block_num'], as_index= False).agg({'item_cnt_day': 'sum'})\n",
    "gb.rename(columns= {'item_cnt_day': 'target_shop'}, inplace= True)\n",
    "all_data = pd.merge(all_data, gb, how= 'left', on= ['shop_id', 'date_block_num']).fillna(0)\n",
    "\n",
    "# sames as above with item-month (item is not included) aggregates\n",
    "gb = sales.groupby(['item_id', 'date_block_num'], as_index= False).agg({'item_cnt_day': 'sum'})\n",
    "gb.rename(columns= {'item_cnt_day': 'target_item'}, inplace= True)\n",
    "all_data = pd.merge(all_data, gb, how= 'left', on= ['item_id', 'date_block_num']).fillna(0)\n",
    "\n",
    "# downcast dtypes from 64 to 32 to save memory\n",
    "all_data = downcast_dtypes(all_data)\n",
    "del grid, gb\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>target</th>\n",
       "      <th>target_shop</th>\n",
       "      <th>target_item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>7738</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7057.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>7737</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7057.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>7770</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7057.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>7664</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7057.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>7814</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7057.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278614</th>\n",
       "      <td>26</td>\n",
       "      <td>21760</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1409.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278615</th>\n",
       "      <td>26</td>\n",
       "      <td>21956</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1409.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278616</th>\n",
       "      <td>26</td>\n",
       "      <td>21976</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1409.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278617</th>\n",
       "      <td>26</td>\n",
       "      <td>21881</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1409.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278618</th>\n",
       "      <td>26</td>\n",
       "      <td>21914</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1409.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>278619 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        shop_id  item_id  date_block_num  target  target_shop  target_item\n",
       "0            28     7738               0     4.0       7057.0         11.0\n",
       "1            28     7737               0    10.0       7057.0         16.0\n",
       "2            28     7770               0     6.0       7057.0         10.0\n",
       "3            28     7664               0     1.0       7057.0          1.0\n",
       "4            28     7814               0     2.0       7057.0          6.0\n",
       "...         ...      ...             ...     ...          ...          ...\n",
       "278614       26    21760              33     0.0       1409.0          1.0\n",
       "278615       26    21956              33     0.0       1409.0          2.0\n",
       "278616       26    21976              33     0.0       1409.0          2.0\n",
       "278617       26    21881              33     0.0       1409.0          2.0\n",
       "278618       26    21914              33     0.0       1409.0          1.0\n",
       "\n",
       "[278619 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b98e65bb35149fc8aa8f4139de0a615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# list of columns that we will use to create lags. \n",
    "# the outcome of this command is the name of the target columns we created\n",
    "cols_to_rename = list(all_data.columns.difference(index_cols))\n",
    "\n",
    "shift_range = [1, 2, 3, 4, 5, 12]\n",
    "\n",
    "# for month_shift in tqdwm_notebook(shift_range)\n",
    "for month_shift in notebook.tqdm(shift_range):\n",
    "    train_shift = all_data[index_cols + cols_to_rename].copy()\n",
    "    \n",
    "    train_shift['date_block_num'] =  train_shift['date_block_num'] + month_shift\n",
    "    \n",
    "    foo = lambda x: '{}_lag_{}'.format(x, month_shift) if x in cols_to_rename else x\n",
    "    train_shift = train_shift.rename(columns= foo)\n",
    "    \n",
    "    all_data = pd.merge(all_data, train_shift, on= index_cols, how= 'left').fillna(0)\n",
    "    \n",
    "del train_shift\n",
    "\n",
    "# dont's use old data from year 2013\n",
    "all_data = all_data[all_data['date_block_num'] >= 12]\n",
    "\n",
    "# list of all lagged features\n",
    "fit_cols = [col for col in all_data.columns if col[-1] in [str(item) for item in shift_range]]   \n",
    "\n",
    "# we will drop these at fitting stage\n",
    "to_drop_cols = list(set(list(all_data.columns)) - (set(fit_cols)|set(index_cols))) + ['date_block_num']\n",
    "\n",
    "# category for each item\n",
    "item_category_mapping = items[['item_id', 'item_category_id']].drop_duplicates()\n",
    "\n",
    "# merge the item_category_mapping into the all data dataframe\n",
    "all_data = pd.merge(all_data, item_category_mapping, how= 'left', on='item_id')\n",
    "all_data = downcast_dtypes(all_data)\n",
    "gc.collect();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>target</th>\n",
       "      <th>target_shop</th>\n",
       "      <th>target_item</th>\n",
       "      <th>target_lag_1</th>\n",
       "      <th>target_item_lag_1</th>\n",
       "      <th>target_shop_lag_1</th>\n",
       "      <th>target_lag_2</th>\n",
       "      <th>target_item_lag_2</th>\n",
       "      <th>target_shop_lag_2</th>\n",
       "      <th>target_lag_3</th>\n",
       "      <th>target_item_lag_3</th>\n",
       "      <th>target_shop_lag_3</th>\n",
       "      <th>target_lag_4</th>\n",
       "      <th>target_item_lag_4</th>\n",
       "      <th>target_shop_lag_4</th>\n",
       "      <th>target_lag_5</th>\n",
       "      <th>target_item_lag_5</th>\n",
       "      <th>target_shop_lag_5</th>\n",
       "      <th>target_lag_12</th>\n",
       "      <th>target_item_lag_12</th>\n",
       "      <th>target_shop_lag_12</th>\n",
       "      <th>item_category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>10994</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6949.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8499.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6454.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>10992</td>\n",
       "      <td>12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6949.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8499.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7521.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>10991</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6949.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8499.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5609.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6753.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7521.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>10988</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8499.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6454.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5609.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6753.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>11002</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6949.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8499.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157945</th>\n",
       "      <td>26</td>\n",
       "      <td>21760</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1409.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157946</th>\n",
       "      <td>26</td>\n",
       "      <td>21956</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1409.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>953.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157947</th>\n",
       "      <td>26</td>\n",
       "      <td>21976</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1409.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1553.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>953.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157948</th>\n",
       "      <td>26</td>\n",
       "      <td>21881</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1409.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1553.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>953.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1358.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157949</th>\n",
       "      <td>26</td>\n",
       "      <td>21914</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1409.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1358.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157950 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        shop_id  item_id  date_block_num  target  target_shop  target_item  \\\n",
       "0            28    10994              12     1.0       6949.0          1.0   \n",
       "1            28    10992              12     3.0       6949.0          4.0   \n",
       "2            28    10991              12     1.0       6949.0          5.0   \n",
       "3            28    10988              12     1.0       6949.0          2.0   \n",
       "4            28    11002              12     1.0       6949.0          1.0   \n",
       "...         ...      ...             ...     ...          ...          ...   \n",
       "157945       26    21760              33     0.0       1409.0          1.0   \n",
       "157946       26    21956              33     0.0       1409.0          2.0   \n",
       "157947       26    21976              33     0.0       1409.0          2.0   \n",
       "157948       26    21881              33     0.0       1409.0          2.0   \n",
       "157949       26    21914              33     0.0       1409.0          1.0   \n",
       "\n",
       "        target_lag_1  target_item_lag_1  target_shop_lag_1  target_lag_2  \\\n",
       "0                0.0                1.0             8499.0           0.0   \n",
       "1                3.0                7.0             8499.0           0.0   \n",
       "2                1.0                3.0             8499.0           0.0   \n",
       "3                2.0                5.0             8499.0           4.0   \n",
       "4                0.0                1.0             8499.0           0.0   \n",
       "...              ...                ...                ...           ...   \n",
       "157945           0.0                0.0                0.0           0.0   \n",
       "157946           0.0                0.0                0.0           0.0   \n",
       "157947           1.0                1.0             1553.0           0.0   \n",
       "157948           0.0                2.0             1553.0           0.0   \n",
       "157949           0.0                0.0                0.0           0.0   \n",
       "\n",
       "        target_item_lag_2  target_shop_lag_2  target_lag_3  target_item_lag_3  \\\n",
       "0                     1.0             6454.0           0.0                0.0   \n",
       "1                     0.0                0.0           0.0                0.0   \n",
       "2                     0.0                0.0           0.0                1.0   \n",
       "3                     5.0             6454.0           5.0                6.0   \n",
       "4                     0.0                0.0           0.0                0.0   \n",
       "...                   ...                ...           ...                ...   \n",
       "157945                0.0                0.0           0.0                1.0   \n",
       "157946                0.0                0.0           0.0                0.0   \n",
       "157947                0.0                0.0           0.0                0.0   \n",
       "157948                3.0             1189.0           0.0                4.0   \n",
       "157949                1.0             1189.0           0.0                0.0   \n",
       "\n",
       "        target_shop_lag_3  target_lag_4  target_item_lag_4  target_shop_lag_4  \\\n",
       "0                     0.0           0.0                0.0                0.0   \n",
       "1                     0.0           0.0                0.0                0.0   \n",
       "2                  5609.0           0.0                2.0             6753.0   \n",
       "3                  5609.0           0.0                2.0             6753.0   \n",
       "4                     0.0           0.0                0.0                0.0   \n",
       "...                   ...           ...                ...                ...   \n",
       "157945             1007.0           0.0                0.0                0.0   \n",
       "157946                0.0           0.0                2.0              953.0   \n",
       "157947                0.0           0.0                1.0              953.0   \n",
       "157948             1007.0           0.0                2.0              953.0   \n",
       "157949                0.0           0.0                0.0                0.0   \n",
       "\n",
       "        target_lag_5  target_item_lag_5  target_shop_lag_5  target_lag_12  \\\n",
       "0                0.0                0.0                0.0            0.0   \n",
       "1                0.0                1.0             7521.0            0.0   \n",
       "2                2.0                4.0             7521.0            0.0   \n",
       "3                0.0                0.0                0.0            0.0   \n",
       "4                0.0                0.0                0.0            0.0   \n",
       "...              ...                ...                ...            ...   \n",
       "157945           0.0                0.0                0.0            1.0   \n",
       "157946           0.0                0.0                0.0            0.0   \n",
       "157947           0.0                0.0                0.0            0.0   \n",
       "157948           0.0                8.0             1358.0            0.0   \n",
       "157949           0.0                2.0             1358.0            0.0   \n",
       "\n",
       "        target_item_lag_12  target_shop_lag_12  item_category_id  \n",
       "0                      0.0                 0.0                37  \n",
       "1                      0.0                 0.0                37  \n",
       "2                      0.0                 0.0                40  \n",
       "3                      0.0                 0.0                40  \n",
       "4                      0.0                 0.0                40  \n",
       "...                    ...                 ...               ...  \n",
       "157945                 1.0              1900.0                41  \n",
       "157946                 0.0                 0.0                61  \n",
       "157947                 0.0                 0.0                61  \n",
       "157948                 0.0                 0.0                40  \n",
       "157949                 3.0              1900.0                38  \n",
       "\n",
       "[157950 rows x 25 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a sake of the programming assignment, let's artificially split the data into train and test. We will treat last month data as the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test `date_block_num` is 33\n"
     ]
    }
   ],
   "source": [
    "# save 'date_block_num', as we can't use them as features, but will need them to split the dataset into parts\n",
    "dates = all_data['date_block_num']\n",
    "\n",
    "last_block = dates.max()\n",
    "print('Test `date_block_num` is %d' % last_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_train = dates[dates < last_block]\n",
    "dates_test = dates[dates == last_block]\n",
    "\n",
    "X_train = all_data.loc[dates <  last_block].drop(to_drop_cols, axis= 1)\n",
    "X_test  = all_data.loc[dates == last_block].drop(to_drop_cols, axis= 1)\n",
    "\n",
    "y_train = all_data.loc[dates <  last_block, 'target'].values\n",
    "y_test  = all_data.loc[dates == last_block, 'target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First level models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to implement a basic stacking scheme. We have a time component here, so we will use ***scheme f)*** from the reading material. Recall, that we always use first level models to build two datasets: test meta-features and 2-nd level train-metafetures. Let's see how we get test meta-features first. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test meta-features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firts, we will run *linear regression* on numeric columns and get predictions for the last month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R-squared for linreg is 0.743180\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train.values, y_train)\n",
    "pred_lr = lr.predict(X_test.values)\n",
    "\n",
    "print('Test R-squared for linreg is %f' % r2_score(y_test, pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we run *LightGBM*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R-squared for LightGBM is 0.736842\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {\n",
    "               'feature_fraction': 0.75,\n",
    "               'metric': 'rmse',\n",
    "               'nthread':1, \n",
    "               'min_data_in_leaf': 2**7, \n",
    "               'bagging_fraction': 0.75, \n",
    "               'learning_rate': 0.03, \n",
    "               'objective': 'mse', \n",
    "               'bagging_seed': 2**7, \n",
    "               'num_leaves': 2**7,\n",
    "               'bagging_freq':1,\n",
    "               'verbose':0 \n",
    "              }\n",
    "\n",
    "# keep in mind that the ytrain is a 1D array\n",
    "model = lgb.train(lgb_params, lgb.Dataset(X_train, label=y_train), 100)\n",
    "pred_lgb = model.predict(X_test)\n",
    "\n",
    "print('Test R-squared for LightGBM is %f' % r2_score(y_test, pred_lgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally concatenate test predictions to get test meta-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_level2 = np.c_[pred_lr, pred_lgb]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train meta-features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now it is your turn to write the code**. You need to implement ***scheme f)*** from the reading material. Here, we will use duration **T** equal to month and **M=15**.  \n",
    "\n",
    "That is, you need to get predictions (meta-features) from *linear regression* and *LightGBM* for months 27, 28, 29, 30, 31, 32. Use the same parameters as in above models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_train_level2 = dates_train[dates_train.isin([27, 28, 29, 30, 31, 32])]\n",
    "\n",
    "# that is how we gt target for the 2nd level dataset\n",
    "y_train_level2 = y_train[dates_train.isin([27, 28, 29, 30, 31, 32])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________\n",
      "27\n",
      "Test R-squared for linreg is 0.485961\n",
      "Test R-squared for LightGBM is 0.271576\n",
      "________________________________________\n",
      "28\n",
      "Test R-squared for linreg is 0.549966\n",
      "Test R-squared for LightGBM is 0.475652\n",
      "________________________________________\n",
      "29\n",
      "Test R-squared for linreg is 0.796330\n",
      "Test R-squared for LightGBM is 0.608881\n",
      "________________________________________\n",
      "30\n",
      "Test R-squared for linreg is 0.799710\n",
      "Test R-squared for LightGBM is 0.639048\n",
      "________________________________________\n",
      "31\n",
      "Test R-squared for linreg is 0.843263\n",
      "Test R-squared for LightGBM is 0.687528\n",
      "________________________________________\n",
      "32\n",
      "Test R-squared for linreg is 0.398219\n",
      "Test R-squared for LightGBM is 0.403944\n"
     ]
    }
   ],
   "source": [
    "#and here we create a 2nd level feature matrix, init it with zeros first\n",
    "X_train_level2 = np.zeros([y_train_level2.shape[0], 2])\n",
    "\n",
    "# Now fill `X_train_level2` with metafeatures\n",
    "for cur_block_num in [27, 28, 29, 30, 31, 32]:\n",
    "    \n",
    "    print('_'*40)\n",
    "    print(cur_block_num)\n",
    "    \n",
    "    '''\n",
    "        1. Split `X_train` into parts\n",
    "           Remember, that corresponding dates are stored in `dates_train` \n",
    "        2. Fit linear regression \n",
    "        3. Fit LightGBM and put predictions          \n",
    "        4. Store predictions from 2. and 3. in the right place of `X_train_level2`. \n",
    "           You can use `dates_train_level2` for it\n",
    "           Make sure the order of the meta-features is the same as in `X_test_level2`\n",
    "    '''      \n",
    "    \n",
    "    #  YOUR CODE GOES HERE\n",
    "    X_train = all_data.loc[dates <  cur_block_num].drop(to_drop_cols, axis= 1)\n",
    "    X_test  = all_data.loc[dates == cur_block_num].drop(to_drop_cols, axis= 1)\n",
    "\n",
    "    y_train = all_data.loc[dates <  cur_block_num, 'target'].values\n",
    "    y_test_cur  = all_data.loc[dates == cur_block_num, 'target'].values\n",
    "    \n",
    "    lr.fit(X_train, y_train)\n",
    "    pred_lr = lr.predict(X_test.values)\n",
    "        \n",
    "    print('Test R-squared for linreg is %f' % r2_score(y_test_cur, pred_lr))\n",
    "    \n",
    "    # keep in mind that the ytrain is a 1D array\n",
    "    model = lgb.train(lgb_params, lgb.Dataset(X_train, label=y_train), 100)\n",
    "    pred_lgb = model.predict(X_test)\n",
    "    \n",
    "    print('Test R-squared for LightGBM is %f' % r2_score(y_test_cur, pred_lgb))\n",
    "    \n",
    "    X_train_level2[dates_train_level2 == cur_block_num] = np.c_[pred_lr, pred_lgb]\n",
    "    \n",
    "# Sanity check\n",
    "# assert np.all(np.isclose(X_train_level2.mean(axis=0), [ 1.50148988,  1.38811989]))\n",
    "# I added this line as in the original script.  Nontheless, the value changed slightly due to\n",
    "# my LightGBM library version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.50148988, 1.38406219])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_level2.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, the ensembles work best, when first level models are diverse. We can qualitatively analyze the diversity by examinig *scatter plot* between the two metafeatures. Plot the scatter plot below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAZ0UlEQVR4nO3df5Ac9Xnn8fdHmzVZbF8WwuISCzoJStYFIiPhDaZOFyrBiQU4NmvOjuGSmMtRp/jOVMWJo7MUXwJOOYdigu2kLodLvnDgi4MBIyskYGPKIiHlCtgrS0LSgYLA2NZKJa3BC47ZgmX13B/TI2aHmdmdHz3d0/N5VU3tzLe7Zx4a7TPf/f5URGBmZsWyJOsAzMys85zczcwKyMndzKyAnNzNzArIyd3MrIB+IusAAE477bRYvnx51mGYmfWUnTt3/iAiRmody0VyX758ORMTE1mHYWbWUyR9t94xN8uYmRWQk7uZWQEtmNwl3SrpmKR9FWV3StqdPJ6RtDspXy5ppuLYZ9MM3szMaltMm/ttwP8EPl8uiIj3l59Luhl4vuL8pyJiTacCNDOz5i2Y3CPiYUnLax2TJOBXgUs6G5aZmbWj3dEyPw8cjYgnK8pWSNoFvAD894j4x1oXStoAbABYtmxZm2GYWVa275rkpgcOcHh6hjOGh9i4fhXja0ezDqvvtZvcrwbuqHh9BFgWEc9KeiuwXdJ5EfFC9YURsRXYCjA2NualKc160PZdk2zetpeZ2TkAJqdn2LxtL4ATfMZaHi0j6SeAK4E7y2UR8VJEPJs83wk8Bby53SDNLJ9ueuDAicReNjM7x00PHMgoIitrZyjkLwFPRMShcoGkEUkDyfOzgZXA0+2FaGZ5dXh6pqly657FDIW8A/gnYJWkQ5KuTQ5dxfwmGYCLgcck7QG+BHwwIp7rZMBmlh9nDA81VW7ds5jRMlfXKf+PNcruAe5pPywz6wUb16+a1+YOMDQ4wMb1qzKMyiAna8uYWW8qd5p6tEz+OLmbWVvG1446meeQ15YxMysgJ3czswJycjczKyAndzOzAnJyNzMrICd3M7MCcnI3MysgJ3czswJycjczKyAndzOzAnJyNzMrICd3M7MCcnI3MysgJ3czswJycjczKyAndzOzAlrMHqq3SjomaV9F2Q2SJiXtTh6XVxzbLOmgpAOS1qcVuJmZ1beYmvttwKU1yj8dEWuSx/0Aks6ltHH2eck1/0vSQKeCNTOzxVnMBtkPS1q+yPe7AvhiRLwEfEfSQeBC4J9ajtDMcm/7rknvo5oz7bS5XyfpsaTZ5pSkbBT4fsU5h5Ky15C0QdKEpImpqak2wjCzLG3fNcnmbXuZnJ4hgMnpGTZv28v2XZNZh9bXWk3utwDnAGuAI8DNSblqnBu13iAitkbEWESMjYyMtBiGmWXtpgcOMDM7N69sZnaOmx44kFFEBi0m94g4GhFzEXEc+Bylphco1dTPqjj1TOBweyGaWZ4dnp5pqty6o6XkLmlpxcv3AOWRNPcCV0k6SdIKYCXwzfZCNLM8O2N4qKly647FDIW8g1KH6CpJhyRdC3xS0l5JjwG/CPwOQETsB+4C/h/wVeBDETFX563NrAA2rl/F0OD8QXFDgwNsXL8qo4gMQBE1m8S7amxsLCYmJrIOw8xa5NEy2ZC0MyLGah1bcCikmdlCxteOOpnnjJcfMDMrICd3M7MCcrOMWQe4zdnyxsndrE3lGZrliTzlGZpAzyd4f2n1Lid3szY1mqHZy4mwF7+0/GX0Kre5m7WpqDM0e21ZAa9xM5+Tu1mbijpDs9e+tHrtyyhtTu5mbcrrDM3tuyZZt2UHKzbdx7otO5quwfbal1avfRmlzcndrE3ja0e58crVjA4PIWB0eIgbr1ydaVtvJ5oo8vqlVU+vfRm1++W7EHeomnVA3mZodqKTt3xer3RQbly/al4HMOT3y6gbndVO7mYF1Kkmirx9aTXSS19G3Rhh5eRuVkBnDA8xWSOR57WJolN65cuoG/0DbnM3K6CF2svTbu+1xrrRP+DkblZAjTp5PR48e93orHazjFlB1WuiKOqM2l7Sjf4BJ3ezPuPx4PmQdv+Am2XM+kyvjQe31ji5m/WZXpucZK1ZsFlG0q3ArwDHIuJnk7KbgHcBLwNPAb8ZEdOSlgOPA+XFHB6JiA+mEHeheCU766ZeGg9urVtwg2xJFwP/Any+Irm/A9gREa9I+hOAiPhoktz/rnzeYvXzBtnVM9WgVIvKevq6WVEVqTLVaIPsBZtlIuJh4Lmqsq9FxCvJy0eAM9uOsk95JTuz7umnYaCdaHP/T8BXKl6vkLRL0j9I+vl6F0naIGlC0sTU1FQHwuhNHrlg1j39VJlqK7lL+hjwCvCFpOgIsCwi1gK/C/y1pH9V69qI2BoRYxExNjIy0k4YPc0jF8y6p58qUy0nd0nXUOpo/bVIGu4j4qWIeDZ5vpNSZ+ubOxFoUXnkgln39FNlqqXkLulS4KPAuyPixYryEUkDyfOzgZXA050ItKjyuBa4WVH1U2VqMUMh7wB+AThN0iHgemAzcBLwoCR4dcjjxcAfSXoFmAM+GBHP1XxjO6FXVrIz63X9NAx0waGQ3dDPQyHNzFrV1lBIMzPrPU7uZmYF5ORuZlZAXvLX2lKkqdxmReLkbi3rxg7uZtYaN8tYy/ppKrdZr3Fyt5b101Rus17j5G4t66ep3Ga9xsndWtZPU7nNeo07VLugqCNK+mkqt1mvcXJPWdFHlHhdHLN8crNMyjyixMyy4OSeMo8oMbMsOLmnzCNKzCwLTu4p84gSM8uCO1RT5hElZpYFJ/cu8IgSq6WoQ2QtH5zczTJQ9CGylr1FtblLulXSMUn7KspOlfSgpCeTn6ck5ZL055IOSnpM0gVpBW/WqzxE1tK22A7V24BLq8o2AV+PiJXA15PXAJcBK5PHBuCW9sM0KxYPkbW0LSq5R8TDwHNVxVcAtyfPbwfGK8o/HyWPAMOSlnYiWLOi8BBZS1s7QyHfFBFHAJKfpyflo8D3K847lJTNI2mDpAlJE1NTU22EYdZ7PETW0pbGOHfVKIvXFERsjYixiBgbGRlJIQyz/BpfO8qNV65mdHgIAaPDQ9x45Wp3plrHtDNa5qikpRFxJGl2OZaUHwLOqjjvTOBwG59jVkgeImtpaqfmfi9wTfL8GuBvKso/kIyauQh4vtx8Y2Zm3bGomrukO4BfAE6TdAi4HtgC3CXpWuB7wPuS0+8HLgcOAi8Cv9nhmM3MbAGLSu4RcXWdQ2+vcW4AH2onKDMza48XDjMzKyAndzOzAnJyNzMrICd3M7MCcnI3MysgJ3czswLyeu4p84YMZpYFJ/cUeUMGM8uKm2VS5A0ZzCwrTu4p8oYMZpYVJ/cmbd81ybotO1ix6T7WbdnB9l2Tdc+tt/FCwILXmpm1w8m9CeU29MnpGYJX29DrJelaGzKULXStmVk7nNyb0GwbeuWGDLW4/d3M0uLk3oRW2tDH147yjU2X1NyeaqFrzcxa5eTehHY2NfaGyGbWTU7uTWhnU+Ne2RC5mQ5jM8svT2JqQnniUSszTtu5tls86cqsOFTaOClbY2NjMTExkXUYfW/dlh1M1ugDGB0e4hubLskgIjNrRNLOiBirdcw19y7olfVlPOnKrDhaTu6SVgF3VhSdDfwhMAz8Z2AqKf/9iLi/5Qh7XC81dZwxPFSz5u5OX7Pe03KHakQciIg1EbEGeCvwIvDl5PCny8f6ObFDb60v0yudvma2sE41y7wdeCoivivVG9Hdn3qpqaMXOn3NbHE6ldyvAu6oeH2dpA8AE8BHIuKH1RdI2gBsAFi2bFmHwsifXmvqGF876mRuVgBtj3OX9Drg3cDdSdEtwDnAGuAIcHOt6yJia0SMRcTYyMhIu2Hklps6zCwLnai5XwZ8OyKOApR/Akj6HPB3HfiMnuWmDjPLQieS+9VUNMlIWhoRR5KX7wH2deAzepqbOsys29pK7pJOBn4Z+K2K4k9KWkNp2fJnqo6ZmVkXtJXcI+JF4Keryn6jrYjMzKxtXjjMzKyAnNzNzArIyd3MrICc3M3MCsjJ3cysgJzczcwKyMndzKyAnNzNzArIyd3MrICc3M3MCsh7qC6g1f1Pe2XfVDMrJif3Blrd/7SX9k01s2Jycq9SWeNeIjEXMe945f6n9WrmjfZNdXI3s25wcq9QXeOuTuxl5Zp4vZp5L+2bambF5A7VCrVq3LUMSHVr5lB/f9S87ptqZsXj5F5hMTXrocGBujX68vXeN9XMsubkXqFezXpAQsDo8BA3Xrma0QVq5uNrR0+cV3md29vNrFvc5l5h4/pV89rSAQRc/baz+MT46nnnVp9XXTP3vqlmlqW2a+6SnpG0V9JuSRNJ2amSHpT0ZPLzlPZDTd/42lH+/VtHUUVZAPfsnGT7rsl557lmbmZ51qma+y9GxA8qXm8Cvh4RWyRtSl5/tEOflaqHnpiiukW91jBG18zNLM/SanO/Arg9eX47MJ7S53SchzGaWRF0IrkH8DVJOyVtSMreFBFHAJKfp1dfJGmDpAlJE1NTUx0IozPqdaoukeY1zZiZ5VknmmXWRcRhSacDD0p6YjEXRcRWYCvA2NhY7bGFGajVqQqlCU2VE5U6veaM16Ixs05qO7lHxOHk5zFJXwYuBI5KWhoRRyQtBY61+zndUk6oH7lrT8OlBzq55szEd5/jnp2TXovGzDpGUWdCzqIull4PLImIHyXPHwT+CHg78GxFh+qpEfHf6r3P2NhYTExMtBxHGlZsuu81Hatlo8NDTNZogx+QOB5Rt+a9bsuOutfVmhg1OjzENzZd0lL81fyXgVnxSNoZEWO1jrVbc38T8GVJ5ff664j4qqRvAXdJuhb4HvC+Nj+n64ZPHuSHL87WPFYrQcOra9HUq3nX65RdaMZru7xKpVn/aSu5R8TTwPk1yp+lVHvvWY3+oKlX065UOXyyXGuud0W99+vUWjSNVqksH1+oRu+av1lv8fIDdTw/U7vWDqWadvXaMbVMTs+cqDXXq+0PDQ5w9dvOSnUtmnp/AZRr8JPTM0TF6+pRQZX/DY3OM7P8cHKvo1GtuTwj9ZSTBxu+x4DUcKXJ8vt8Ynx1qjNeG62Z06hGX7ZQzd/M8sdry9Sxcf0qNn5pD7Nzr20umZyeWVRim4uoW2sWzOssTXPGa63hnUODA3W/dKpj9sQus97jmnsd42tHuem959etnU9Oz9TtcC0bHR7Kxdru9dbCWWh1y3qvFyo3s+y55t5AZW263jDGegaX6ESb+UIrSHZDvb8MFhNbvZq/16c3yy8n90VqJrEPDS7hxivfMi+Z5nGkSeWer41iW+x5ZpYfbU1i6pQ8TmKqds7m+2sOVxSl5gknPTPrtjQnMRXGQuO4641rD+jYLFIzs05xhyqLG8ddr/OxXrmZWZb6Prlv3zXJR+7aU3Mc9+Ztj5147U2vzayX9HVyL9fY6zW5zMwe59w/+Arbd016az0z6yl93aHazPDGkweX8D+qRsCYmWWpUYdqX9fcm5lh+eLscTbevcfrqZhZT+jr5N7sDMvZ4+H1VMysJ/R1ct+4fhVq8prySo9mZnnWV+Pca41l/7fnnMo3nnquqff58J27ueHe/fzK+Ut56IkpT2Ays9zpmw7V6t2I0jA0OOARNGbWNe5Qpfaa5J3mNc7NLC/6Jrl3a+1xr3FuZnnQcnKXdJakhyQ9Lmm/pN9Oym+QNClpd/K4vHPhtmb7rkmWqNmu09Z4jXMzy4N2OlRfAT4SEd+W9EZgp6QHk2Ofjog/bT+8xsodpJPTMyc2mR6t6thcaBZqJ3k5AjPLi5aTe0QcAY4kz38k6XGgaz2J1R2k5eQ9OT3Dxrv38PG/3c/0i7MsSZJ+msrL/nq0jJnlRUeGQkpaDqwFHgXWAddJ+gAwQal2/8Ma12wANgAsW7as6c9s1EE6ezxObIGXdmIfHhpk9/XvSPUzzMya1XaHqqQ3APcAH46IF4BbgHOANZRq9jfXui4itkbEWESMjYyMNP25eei4HFwibnj3eVmHYWb2Gm0ld0mDlBL7FyJiG0BEHI2IuYg4DnwOuLD9MF8rq47Lcrfs6PAQN73vfDfDmFkutTNaRsBfAo9HxKcqypdWnPYeYF/r4dVXa331bghgQHL7upnlWjtt7uuA3wD2StqdlP0+cLWkNZTy4DPAb7UVYR2VmzZXjpYZHhrkxy+/wuxcem3tcxFs3rZ3XhxmZnlSyOUHqteQWeya7c0aHR7y/qlmlpm+2yB7fO3ovBr18k33pfI5eejUNTOrpS+WHxgeGkzlfT0b1czyqi+SexrDFT0b1czyrJDNMr/8qb/nyWM/PvF65emv59cvWsZfPfK9jrx/9RIHZmZ5U7jkXp3YAZ489mNemJntyPsL3IlqZrlXuGaZ6sRedvRHL3fk/d3Obma9oFDJPe29Td3Obma9olDJPc1dkAYkb6FnZj2jUMk9rclKUJqV6sRuZr2iUMk9bT/zB19JvenHzKwTnNybMDN7nM3b9jrBm1nuFW4oZNpmZue44d7989au8Zh3M8sbJ/cWTM/MMp2Mm5+cnvEKkWaWO26W6YCZ2blUR+qYmTXLyb1DvEKkmeWJk3sTBiROObn2CpOeuWpmeeLkvkiDA+LmXz2f69913mu29/PMVTPLG3eoLsIpJw9y/bvOm9dh6tEyZpZnqSV3SZcCfwYMAP87Irak9VkAb7n+q6m99zvfsnRe8q7e6cnMLG9SaZaRNAD8BXAZcC6lTbPPTeOzyl54aS61977j0e+n9t5mZmlIq839QuBgRDwdES8DXwSuSOmzUjeXg03EzcyakVZyHwUqq7uHkrITJG2QNCFpYmpqKqUwOmNAyjoEM7OmpJXca2XDedXfiNgaEWMRMTYyMpJSGJ1x9dvOyjoEM7OmpJXcDwGVGfFM4HBKn9URorQ36rpzTj1RUx+Q+PWLlvGJ8dXZBmdm1qS0Rst8C1gpaQUwCVwF/IeUPguAZ7a8k+Wb7mvp2gGJp268vMMRmZllJ5Wae0S8AlwHPAA8DtwVEfvT+KxKz2x5J595/5qmr3Ozi5kVTWozVCPi/oh4c0ScExF/nNbnVBtfO1p3iYBa3OxiZkVUyOUHrn/XeTV7dCsNDw3ymfevcWI3s0IqZHIfXzvKr120rOE50zOzbLx7j3dVMrNCKmRyB/jE+Go+8/41DA/Vb6KZPR5eh93MCqmwyR1KNfjd17+jYRON12E3syIqdHIva7TWutdhN7Mi6ovkvnH9KgYHXlt/H1wir8NuZoXUF+u5l5fn/fjf7ueHL5Y2th4eGuSGd5/npXvNrJD6IrmD12A3s/7SF80yZmb9xsndzKyAnNzNzArIyd3MrICc3M3MCkiRg/1BJU0B3+3w254G/KDD79lJjq99eY/R8bUn7/FB9jH+64iouZVdLpJ7GiRNRMRY1nHU4/jal/cYHV978h4f5DtGN8uYmRWQk7uZWQEVOblvzTqABTi+9uU9RsfXnrzHBzmOsbBt7mZm/azINXczs77l5G5mVkCFS+6SLpV0QNJBSZuyjqdM0jOS9kraLWkiKTtV0oOSnkx+ntLFeG6VdEzSvoqymvGo5M+Te/qYpAsyiu8GSZPJPdwt6fKKY5uT+A5IWt+F+M6S9JCkxyXtl/TbSXku7mGD+PJ0D39S0jcl7Uli/HhSvkLSo8k9vFPS65Lyk5LXB5PjyzOK7zZJ36m4h2uS8q7/njQUEYV5AAPAU8DZwOuAPcC5WceVxPYMcFpV2SeBTcnzTcCfdDGei4ELgH0LxQNcDnwFEHAR8GhG8d0A/F6Nc89N/l+fBKxI/g0MpBzfUuCC5PkbgX9O4sjFPWwQX57uoYA3JM8HgUeTe3MXcFVS/lngvyTP/yvw2eT5VcCdGcV3G/DeGud3/fek0aNoNfcLgYMR8XREvAx8Ebgi45gauQK4PXl+OzDerQ+OiIeB5xYZzxXA56PkEWBY0tIM4qvnCuCLEfFSRHwHOEjp30JqIuJIRHw7ef4j4HFglJzcwwbx1ZPFPYyI+Jfk5WDyCOAS4EtJefU9LN/bLwFvl9Roi+S04qun678njRQtuY8C3694fYjG/6C7KYCvSdopaUNS9qaIOAKlX0bg9MyiaxxPnu7rdcmfvLdWNGNlGl/SPLCWUs0ud/ewKj7I0T2UNCBpN3AMeJDSXwzTEfFKjThOxJgcfx746W7GFxHle/jHyT38tKSTquOrEXvXFS251/oWz8tYz3URcQFwGfAhSRdnHVAT8nJfbwHOAdYAR4Cbk/LM4pP0BuAe4MMR8UKjU2uUpR5jjfhydQ8jYi4i1gBnUvpL4WcaxNH1GKvjk/SzwGbg3wA/B5wKfDSr+BopWnI/BJxV8fpM4HBGscwTEYeTn8eAL1P6h3y0/Gdb8vNYdhFCg3hycV8j4mjyy3Yc+ByvNhtkEp+kQUqJ8wsRsS0pzs09rBVf3u5hWURMA39Pqa16WFJ5C9DKOE7EmBz/KRbfdNep+C5NmrwiIl4C/g85uYfVipbcvwWsTHrbX0ep0+XejGNC0uslvbH8HHgHsI9SbNckp10D/E02EZ5QL557gQ8kowEuAp4vNz10U1X75Xso3cNyfFcloylWACuBb6Yci4C/BB6PiE9VHMrFPawXX87u4Yik4eT5EPBLlPoGHgLem5xWfQ/L9/a9wI5IejK7GN8TFV/eotQfUHkPM/89OSHL3tw0HpR6rP+ZUtvdx7KOJ4npbEojEfYA+8txUWov/DrwZPLz1C7GdAelP8tnKdU4rq0XD6U/N/8iuad7gbGM4vu/yec/RukXaWnF+R9L4jsAXNaF+P4dpT+5HwN2J4/L83IPG8SXp3v4FmBXEss+4A+T8rMpfbEcBO4GTkrKfzJ5fTA5fnZG8e1I7uE+4K94dURN139PGj28/ICZWQEVrVnGzMxwcjczKyQndzOzAnJyNzMrICd3M7MCcnI3MysgJ3czswL6/6IOKXJhTg+ZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_train_level2[:, 0], X_train_level2[:, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when the meta-features are created, we can ensemble our first level models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with simple linear convex mix:\n",
    "\n",
    "$$\n",
    "mix= \\alpha\\cdot\\text{linreg_prediction}+(1-\\alpha)\\cdot\\text{lgb_prediction}\n",
    "$$\n",
    "\n",
    "We need to find an optimal $\\alpha$. And it is very easy, as it is feasible to do grid search. Next, find the optimal $\\alpha$ out of `alphas_to_try` array. Remember, that you need to use train meta-features (not test) when searching for $\\alpha$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.763000; Corresponding r2 score on train: 0.627463\n"
     ]
    }
   ],
   "source": [
    "alphas_to_try = np.linspace(0, 1, 1001)\n",
    "\n",
    "# YOUR CODE GOES HERE\n",
    "best_alpha = 0 \n",
    "r2_train_simple_mix = 0\n",
    "\n",
    "for alpha in alphas_to_try:\n",
    "    mix = alpha * X_train_level2[:, 0] + (1 - alpha) * X_train_level2[:, 1]\n",
    "    r2 = r2_score(y_train_level2, mix)\n",
    "    if r2 > r2_train_simple_mix:\n",
    "        best_alpha = alpha\n",
    "        r2_train_simple_mix = r2\n",
    "        \n",
    "print('Best alpha: %f; Corresponding r2 score on train: %f' % (best_alpha, r2_train_simple_mix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the $\\alpha$ you've found to compute predictions for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R-squared for simple mix is 0.781679\n"
     ]
    }
   ],
   "source": [
    "test_preds = best_alpha * X_test_level2[:, 0] + (1 - best_alpha) * X_test_level2[:, 1] # YOUR CODE GOES HERE\n",
    "r2_test_simple_mix = r2_score(y_test, test_preds)# YOUR CODE GOES HERE\n",
    "\n",
    "print('Test R-squared for simple mix is %f' % r2_test_simple_mix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will try a more advanced ensembling technique. Fit a linear regression model to the meta-features. Use the same parameters as in the model above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train_level2, y_train_level2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient:            [0.80463019 0.10013661]\n",
      "Normalized Coefficient: [0.88932329 0.11067671]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficient:            {}'.format(lr.coef_))\n",
    "print('Normalized Coefficient: {}'.format(lr.coef_ / lr.coef_.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute R-squared on the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R-squared for stacking is 0.632206\n",
      "Test  R-squared for stacking is 0.771887\n"
     ]
    }
   ],
   "source": [
    "train_preds = lr.predict(X_train_level2) # YOUR CODE GOES HERE\n",
    "r2_train_stacking = r2_score(y_train_level2, train_preds) # YOUR CODE GOES HERE\n",
    "\n",
    "test_preds = lr.predict(X_test_level2) # YOUR CODE GOES HERE\n",
    "r2_test_stacking = r2_score(y_test, test_preds)# YOUR CODE GOES HERE\n",
    "\n",
    "print('Train R-squared for stacking is %f' % r2_train_stacking)\n",
    "print('Test  R-squared for stacking is %f' % r2_test_stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_course_coursera",
   "language": "python",
   "name": "kaggle_course_coursera"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
